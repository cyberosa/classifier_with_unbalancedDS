{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"training_df2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint_confusion_matrix_and_report(model, X0_test, y0_test):\n",
    "    y_pred = model.predict(X0_test)\n",
    "    cm2 = confusion_matrix(y0_test, y_pred.round())\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm2, annot=True, ax = ax, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['no-conversion', 'conversion']); ax.yaxis.set_ticklabels(['no-conversion', 'conversion'])\n",
    "    prec_rec = classification_report(y_pred, y0_test, target_names=['no-conversion', 'conversion'])\n",
    "    print(prec_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']  # Labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X0_train, y0_train):\n",
    "    start = time()\n",
    "    model.fit(X0_train,y0_train)\n",
    "    end = time()\n",
    "    result = end - start\n",
    "    print('Training time = %.3f seconds' % result)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before undersampling: \", Counter(y_train))\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "print(\"After undersampling: \", Counter(y_train_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 400, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "# letÂ´s try first with the resample dataset\n",
    "start = time()\n",
    "rf_random.fit(X_train_under, y_train_under)\n",
    "end = time()\n",
    "result = end - start\n",
    "print('Training time = %.3f seconds' % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(n_estimators= 88,\n",
    " min_samples_split= 10,\n",
    " min_samples_leaf= 4,\n",
    " max_features= 'sqrt',\n",
    " max_depth= 80,\n",
    " bootstrap= True,\n",
    " n_jobs=4)\n",
    "bm = fit_model(best_model, X_train_under, y_train_under)\n",
    "paint_confusion_matrix_and_report(bm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the same configuration as for the other dataset\n",
    "best_model = RandomForestClassifier(n_estimators= 361,\n",
    " min_samples_split= 5,\n",
    " min_samples_leaf= 4,\n",
    " max_features= 'auto',\n",
    " max_depth= 10,\n",
    " bootstrap= False,\n",
    " n_jobs=4)\n",
    "bm = fit_model(best_model, X_train_under, y_train_under)\n",
    "paint_confusion_matrix_and_report(bm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [4, 5, 10],\n",
    "    'n_estimators': [200, 300, 400]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestClassifier()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train_under, y_train_under)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(n_estimators= 400,\n",
    " min_samples_split= 10,\n",
    " min_samples_leaf= 3,\n",
    " max_features= 'auto',\n",
    " max_depth= 20,\n",
    " bootstrap= False,\n",
    " n_jobs=4)\n",
    "fm = fit_model(final_model, X_train_under, y_train_under)\n",
    "paint_confusion_matrix_and_report(fm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Not much improvement here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can we do with this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous initial analysis and exploration of the dataset, there are several conclusions that we can already share:\n",
    "- Before the year 2014 there were no lead conversions and data was scarce.\n",
    "- There are many features with geographical information of the lead that is redundant.\n",
    "- We did not find a strong correlation between the selected features and the value to predict.\n",
    "- The dataset is imbalanced having many more labels with 0 than with 1. This was somehow expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place for improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far given the provided features the only patterns you might find are those entirely related with the campaign (given just the name), lead_source and little more... which means your focus in on the campaign and all the configuration around it. This is a fair point and strategy to follow, given the things you have control of.\n",
    "\n",
    "However there could be potential extra successful factors that maybe have nothing to do with the campaign or those external factors and come directly from the user interaction with the product. If you enjoy and you trust a product you have a higher probability to pay for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../training_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current total percentage of converted leads\n",
    "1115 * 100 / 722245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With just 15% of converted leads it is going to be difficult to predict anything. We need to follow some of the techniques to correct this imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification problems, a disparity in the frequencies of the observed classes can have a significant negative impact on model fitting. One technique for resolving such a class imbalance is to subsample the training data in a manner that mitigates the issues. Examples of sampling methods for this purpose are:\n",
    "\n",
    "* under-sampling: randomly subset all the classes in the training set so that their class frequencies match the least prevalent class. For example, suppose that 80% of the training set samples are the first class and the remaining 20% are in the second class. Down-sampling would randomly sample the first class to be the same size as the second class (so that only 40% of the total training set is used to fit the model). \n",
    "* over-sampling: randomly sample (with replacement) the minority class to be the same size as the majority class. Techniques such as SMOTE, down-sample the majority class and synthesizes new data points in the minority class. \n",
    "* hybrid methods: SMOTEENN combines over- and under-sampling using SMOTE and Edited Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LetÂ´s try to build different models using these correction techniques. We will compare the accuracy of each model and check if there is place to build something valuable here or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix gives us an idea how well we are predicting both types of leads, the one that is not converting (0) and the one that is converting (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint_confusion_matrix_and_report(model, X0_test, y0_test):\n",
    "    y_pred = model.predict(X0_test)\n",
    "    cm2 = confusion_matrix(y0_test, y_pred.round())\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm2, annot=True, ax = ax, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['no-conversion', 'conversion']); ax.yaxis.set_ticklabels(['no-conversion', 'conversion'])\n",
    "    prec_rec = classification_report(y_pred, y0_test, target_names=['no-conversion', 'conversion'])\n",
    "    print(prec_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "345 * 100 / 217008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X0_train, y0_train):\n",
    "    start = time()\n",
    "    model.fit(X0_train,y0_train)\n",
    "    end = time()\n",
    "    result = end - start\n",
    "    print('Training time = %.3f seconds' % result)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95.146 seconds for just 1 job\n",
    "clf=RandomForestClassifier(n_estimators=100, n_jobs=4)\n",
    "\n",
    "clf_n = fit_model(clf, X_train, y_train)\n",
    "paint_confusion_matrix_and_report(clf_n, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is really bad since it is predicting most of the leads as not converted (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before undersampling: \", Counter(y_train))\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "print(\"After undersampling: \", Counter(y_train_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_d = fit_model(clf, X_train_under, y_train_under)\n",
    "paint_confusion_matrix_and_report(clf_d, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improved a bit the detection of leads but with the price of increasing false positives. Classifying many as successful converted leads (value 1) when they were not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before undersampling: \", Counter(y_train))\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(\"After undersampling: \", Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_s = fit_model(clf, X_train_smote, y_train_smote)\n",
    "paint_confusion_matrix_and_report(clf_s, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before undersampling: \", Counter(y_train))\n",
    "sme = SMOTEENN(random_state=42)\n",
    "X_train_sme, y_train_sme = smote.fit_resample(X_train, y_train)\n",
    "print(\"After undersampling: \", Counter(y_train_sme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sm = fit_model(clf, X_train_sme, y_train_sme)\n",
    "paint_confusion_matrix_and_report(clf_sm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before undersampling: \", Counter(y_train))\n",
    "over = SMOTE(sampling_strategy=0.4)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X_train_s, y_train_s = over.fit_resample(X_train, y_train)\n",
    "X_train_comb, y_train_comb = under.fit_resample(X_train_s, y_train_s)\n",
    "print(\"After undersampling: \", Counter(y_train_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_c = fit_model(clf, X_train_comb, y_train_comb)\n",
    "paint_confusion_matrix_and_report(clf_c, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 400, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "# letÂ´s try first with the resample dataset\n",
    "start = time()\n",
    "rf_random.fit(X_train_under, y_train_under)\n",
    "end = time()\n",
    "result = end - start\n",
    "print('Training time = %.3f seconds' % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(n_estimators= 361,\n",
    " min_samples_split= 5,\n",
    " min_samples_leaf= 4,\n",
    " max_features= 'auto',\n",
    " max_depth= 10,\n",
    " bootstrap= False,\n",
    " n_jobs=4)\n",
    "bm = fit_model(best_model, X_train_under, y_train_under)\n",
    "paint_confusion_matrix_and_report(bm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [4, 5, 10],\n",
    "    'n_estimators': [200, 300, 400]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a based model\n",
    "rf = RandomForestClassifier()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train_under, y_train_under)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestClassifier(n_estimators= 200,\n",
    " min_samples_split= 4,\n",
    " min_samples_leaf= 5,\n",
    " max_features= 'auto',\n",
    " max_depth= 5,\n",
    " bootstrap= False,\n",
    " n_jobs=4)\n",
    "fm = fit_model(final_model, X_train_under, y_train_under)\n",
    "paint_confusion_matrix_and_report(fm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save\n",
    "joblib.dump(fm, \"final_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a pure classifier we found out that the downsampling technique gave better results with the price of increasing false positives. We should need to check this with the client if that is accepted or not. \n",
    "The SMOTE technique helped also identifying also a lot of converted leads, up to aprox. 2/3 in the best case run. \n",
    "We tried some hyperparameter tuning but due to computer performance limitations could not investigate a wide range of values. The found best model improved precision on the converted leads by almost 0.10% in the end.\n",
    "However we would like to explore a more complicated approach, for instance combining a clustering of leads with a classifier per cluster and compare results with this baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://towardsdatascience.com/how-to-deal-with-imbalanced-data-in-python-f9b71aba53eb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multi-core-machine-learning-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://glemaitre.github.io/imbalanced-learn/api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://vitalflux.com/micro-average-macro-average-scoring-metrics-multi-class-classification-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
